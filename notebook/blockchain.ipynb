{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blockchain analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic setup\n",
    "\n",
    "Here we will import the `pyspark` module and set up a `SparkSession`. By default, we'll use a `SparkSession` running locally, with one Spark executor, but the `local[4]` can be changed with the ip of the Spark master.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .master(\"local[4]\") \\\n",
    "                    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "To obtain the graph representing the transaction in the Bitcoin network, we need to load sets of nodes representing the addresses (fingerprints of the public keys), transactions and blocks. We also need the set of edges representing the relations between entities. For this example we will use following parquet files that were generated from the blockchain data by this [converter](https://github.com/Jiri-Kremser/bitcoin-insights/tree/master/parquet-converter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = spark.read.load(\"/tmp/addresses.parquet\")\n",
    "addresses.show(5)\n",
    "\n",
    "blocks = spark.read.load(\"/tmp/blocks.parquet\")\n",
    "blocks.show(5)\n",
    "\n",
    "transactions = spark.read.load(\"/tmp/transactions.parquet\")\n",
    "transactions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unify "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allNodes = addresses.withColumn(\"type\", lit(\"A\")) \\\n",
    "                    .union(blocks) \\\n",
    "                    .union(transactions.withColumn(\"type\", lit(\"T\"))) \\\n",
    "                    .withColumnRenamed(\"address\", \"id\")\n",
    "\n",
    "allNodes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_edges = spark.read.load(\"/tmp/edges.parquet\") \\\n",
    "                      .cache()\n",
    "raw_edges.show(5)\n",
    "raw_edges.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the graph representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphframes import *\n",
    "\n",
    "g = GraphFrame(allNodes, raw_edges).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the vertex degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "update_type = udf(lambda t: t if t == 'A' or t == 'T' else 'B', StringType())\n",
    "\n",
    "\n",
    "vertexDegreesAndIds = g.inDegrees.join(g.outDegrees, \"id\").join(g.vertices, \"id\")\n",
    "vertexDegrees = vertexDegreesAndIds.drop(\"id\") \\\n",
    "                                   .withColumn('type', update_type(col(\"type\")))\n",
    "\n",
    "vertexDegrees.sort(desc(\"inDegree\")).show(2, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate some basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vertexDegrees.groupBy(\"type\") \\\n",
    "             .agg(avg(col(\"inDegree\")), stddev(col(\"inDegree\")), \\\n",
    "                  avg(col(\"outDegree\")), stddev(col(\"outDegree\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find some patterns in the graph\n",
    "It uses simple ASCII-like DSL and because it's all Dataframe based, it optimizes the query execution by the Catalyst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "motifs = g.find(\"(address)-[e1]->(tx);(block)-[e2]->(tx);(tx)-[e3]->(dstAddress)\") \\\n",
    "                       .filter(\"address.type = 'A'\") \\\n",
    "                       .filter(\"tx.type = 'T'\") \\\n",
    "                       .filter(\"e1.value < 10000\") \\\n",
    "                       .filter(\"block.type > unix_timestamp('2013-01-01 00:00:00')\") \\\n",
    "                       .filter(\"block.type < unix_timestamp('2014-01-01 00:00:00')\") \\\n",
    "                       .filter(\"dstAddress.type = 'A'\") \\\n",
    "                       .filter(\"e3.value < 10000\") \\\n",
    "                       .cache()\n",
    "motifs.selectExpr(\"e1.src as src_address\" ,\"e1.value as src_value\",\n",
    "                  \"e3.value as dst_value\", \"e3.dst as dst_address\").show()\n",
    "motifs.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization methods\n",
    "\n",
    "Our data contain a lot of nodes and edges so let's show only a small fraction of the transaction graph. We will show all the outgoing transaction of particular bitcoin address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "import random\n",
    "\n",
    "vertexOutDegrees = g.outDegrees\n",
    "txs = vertexOutDegrees.join(allNodes, vertexOutDegrees.id == allNodes.id) \\\n",
    "                               .filter(col(\"type\") == \"T\") \\\n",
    "                               .orderBy(\"outDegree\", ascending=False)\n",
    "\n",
    "# feel free to use any tx that is present in the dataset\n",
    "tx = txs.take(1000)[800].id\n",
    "\n",
    "inputs = g.find(\"(input)-[e]->(tx)\") \\\n",
    "             .filter(col(\"tx.id\") == tx) \\\n",
    "             .filter(col(\"input.type\") == \"A\")\n",
    "        \n",
    "outputs = g.find(\"(tx)-[e]->()\") \\\n",
    "             .filter(col(\"tx.id\") == tx)\n",
    "\n",
    "def node_to_dict(r):\n",
    "    return {\n",
    "        'id': r[0],\n",
    "        'label': '<font color=\"red\">' + r[0] + '</font>',\n",
    "        'type': r[1],\n",
    "        'color': '#090' if r[1] == \"in\" else '#900',\n",
    "        'x': random.uniform(0,1) + (-1 if r[1] == \"in\" else 1),\n",
    "        'y': random.uniform(0,1),\n",
    "        'size': random.uniform(0.2,1)\n",
    "    }\n",
    "\n",
    "sub_nodes = inputs.select(concat(lit(\"in\"), col(\"e.src\")), lit(\"in\")) \\\n",
    "                  .withColumnRenamed(\"src\", \"id\") \\\n",
    "                  .union(outputs.select(concat(lit(\"out\"), col(\"e.dst\")), \\\n",
    "                                        lit(\"out\")).withColumnRenamed(\"dst\", \"id\")) \\\n",
    "                  .distinct()\n",
    "        \n",
    "sub_edges = inputs.select(concat(lit(\"in\"), col(\"e.src\")), lit(tx)) \\\n",
    "                  .union(outputs.select(lit(tx), concat(lit(\"out\"), col(\"e.dst\"))))\n",
    "\n",
    "target_nodes_dict = map(node_to_dict, sub_nodes.collect())\n",
    "\n",
    "\n",
    "def edge_to_dict(i, r):\n",
    "    return {\n",
    "        'id': i,\n",
    "        'source': r[0],\n",
    "        'target': r[1]\n",
    "    }\n",
    "\n",
    "sub_edges_dict = [edge_to_dict(i, r) for i, r in enumerate(sub_edges.collect())]\n",
    "\n",
    "target_nodes_dict.append({\n",
    "    'id': tx,\n",
    "    'label': '<font color=\"red\">' + tx + '</font>',\n",
    "    'color': '#999',\n",
    "    'x': 0,\n",
    "    'y': 0.5,\n",
    "    'size': 2\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmajs library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to show the data using the [sigmajs](http://sigmajs.org) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "require.config({\n",
    "    paths: {\n",
    "        sigmajs: 'https://cdnjs.cloudflare.com/ajax/libs/sigma.js/1.2.0/sigma.min',\n",
    "        force: 'https://unpkg.com/3d-force-graph@1.31.1/dist/3d-force-graph.min'\n",
    "    }\n",
    "});\n",
    "\n",
    "require(['sigmajs']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from string import Template\n",
    "import json\n",
    "\n",
    "js_text_template = Template(open('js/sigma-graph.js','r').read())\n",
    "\n",
    "graph_data = { 'nodes': target_nodes_dict, 'edges': sub_edges_dict }\n",
    "\n",
    "js_text = js_text_template.substitute({'graph_data': json.dumps(graph_data),\n",
    "                                       'container': 'graph-div'})\n",
    "\n",
    "html_template = Template('''\n",
    "<div id=\"graph-div\" style=\"height:400px\"></div>\n",
    "<script> $js_text </script>\n",
    "''')\n",
    "\n",
    "HTML(html_template.substitute({'js_text': js_text}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ForceGraph3D library\n",
    "\n",
    "https://github.com/vasturiano/3d-force-graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = { 'nodes': target_nodes_dict, 'links': sub_edges_dict }\n",
    "json_data = json.dumps(graph_data)\n",
    "\n",
    "html_template = Template('''\n",
    "<div id=\"3d-graph\"></div>\n",
    "<script>\n",
    "require(['force'], function(ForceGraph3D) {\n",
    "\n",
    "    const open = (node) => {\n",
    "      console.log(node.type);\n",
    "      let id;\n",
    "      if (node.type === 'out') {\n",
    "        id = 'address/' + node.id.substring(3);\n",
    "      } else if (node.type === 'in') {\n",
    "        id = 'address/' + node.id.substring(2);\n",
    "      } else {\n",
    "        id = 'tx/' + node.id;\n",
    "      }\n",
    "      window.open('https://blockchain.info/' + id , '_blank');\n",
    "    }\n",
    "\n",
    "    const Graph = ForceGraph3D()(document.getElementById('3d-graph'))\n",
    "                                         .width(980)\n",
    "                                         .height(700)\n",
    "                                         .onNodeClick(open)\n",
    "                                         .cameraPosition({ z: 200 })\n",
    "                                         .backgroundColor('#fff')\n",
    "                                         .graphData($json_data)\n",
    "                                         .nodeLabel('label')\n",
    "});\n",
    "</script>\n",
    "''')\n",
    "\n",
    "HTML(html_template.substitute({'json_data': json_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = raw_edges.sample(False, 0.0015).collect()\n",
    "foo_dict = map((lambda row: {'source': row[0], 'target': row[1]}) , sample_data)\n",
    "foo_dict2 = map((lambda row: {'id' : row[0]}) , sample_data) + map((lambda row: {'id' : row[1]}) , sample_data)\n",
    "foo_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = { 'nodes': foo_dict2, 'links': foo_dict }\n",
    "json_data = json.dumps(graph_data)\n",
    "\n",
    "html_template = Template('''\n",
    "<div id=\"3d-graph2\"></div>\n",
    "<script>\n",
    "require(['force'], function(ForceGraph3D) {\n",
    "\n",
    "    const Graph = ForceGraph3D()(document.getElementById('3d-graph2'))\n",
    "                                         .width(980)\n",
    "                                         .height(700)\n",
    "                                         .onNodeClick(open)\n",
    "                                         .cameraPosition({ z: 2000 })\n",
    "                                         .backgroundColor('#fff')\n",
    "                                         .graphData($json_data)\n",
    "                                         .nodeLabel('label')\n",
    "});\n",
    "</script>\n",
    "''')\n",
    "\n",
    "HTML(html_template.substitute({'json_data': json_data}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "transactions.join(vertexDegreesAndIds, transactions.hash == vertexDegreesAndIds.id) \\\n",
    "            .filter(col(\"inDegree\") > 10) \\\n",
    "            .filter(col(\"outDegree\") > 10) \\\n",
    "            .select(\"id\") \\\n",
    "            .show(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networkx & matplotlib\n",
    "Or we can visualize using `networkx` and `matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(sub_edges.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "import matplotlib.pyplot as plt\n",
    "options = {\n",
    "    'node_color': 'g',\n",
    "    'node_size': 70,\n",
    "    'width': 0.2,\n",
    "    'node_shape': 'd',\n",
    "    'with_labels': False,\n",
    "    'font_size': 5,\n",
    "}\n",
    "nx.draw(G, **options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also show some random sub-graph using random layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "hash = lambda str: long(hashlib.md5(str).hexdigest()[:24], 24)\n",
    "\n",
    "sample_data = raw_edges.sample(False, 0.0004).collect()\n",
    "\n",
    "G2 = nx.Graph()\n",
    "G2.add_edges_from(map((lambda row: [hash(row[0]), hash(row[1])]), sample_data))\n",
    "\n",
    "options = {\n",
    "    'node_color': 'g',\n",
    "    'node_size': 1,\n",
    "    'width': 0.05,\n",
    "    'node_shape': 'o',\n",
    "    'vmin': 100.1,\n",
    "    'vmax': 10.1,\n",
    "    'with_labels': False,\n",
    "}\n",
    "nx.draw_random(G2, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "nx.draw_shell(G2, **options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using spring algorithm\n",
    "\n",
    "**Warning: this may take couple of minutes to render**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "nx.draw_spring(G2, **options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunatelly, the plotting mechanism in `networkx` doesn't support the zooming, but it's possible to export the data and explore them by tools like `Gephi`."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "589px",
    "left": "0px",
    "right": "1177.56px",
    "top": "107px",
    "width": "166px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
